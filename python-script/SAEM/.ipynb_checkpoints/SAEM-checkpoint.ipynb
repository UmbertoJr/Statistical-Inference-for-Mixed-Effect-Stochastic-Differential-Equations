{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from particle_markov_chain_monte_carlo import Particle_marginal_Metropolis_Hastings, dati\n",
    "from scipy.optimize import minimize,  differential_evolution, fmin\n",
    "from scipy.stats import norm, multivariate_normal\n",
    "\n",
    "class Stochasti_Approximation_Expectation_Maximization(dati):\n",
    "    def __init__(self, turni_da_ottimizzare = 10, modificare_il_lambda_a = 6):\n",
    "        self.M = turni_da_ottimizzare\n",
    "        self.M1 = modificare_il_lambda_a\n",
    "        \n",
    "        self.PMCMC = Particle_marginal_Metropolis_Hastings()  #number_of_iterations=1000\n",
    "        \n",
    "        dati.__init__(self); \n",
    "        \n",
    "        self.PhiALL = np.zeros((self.M, 6, 2))\n",
    "        self.XALL = np.zeros((self.M, 6, 18))\n",
    "        \n",
    "        self.PARMIN = [0.01, 1e-5, 0.0001, 1e-6, 0.0001, 1e-4] ; self.PARMAX = [1, 1e-1, 0.5, 1, 1, 1e-3]\n",
    "        self.bounds = []\n",
    "        for i in range(6):\n",
    "            self.bounds.append(tuple([self.PARMIN[i], self.PARMAX[i]]))\n",
    "        \n",
    "        \n",
    "    def run(self, theta_init):\n",
    "        self.theta_choose = theta_init\n",
    "        for iterazione in range(0, self.M):\n",
    "            print(\"### ottimizazione iterazione : \", iterazione)\n",
    "            self.iterazione = iterazione\n",
    "            for subject in range(1,7):\n",
    "                                \n",
    "                phi, X = self.PMCMC.sample_PMCMC(subject, self.theta_choose)\n",
    "                self.PhiALL[iterazione, subject-1, :] = phi  #self.PMCMC.phi_PMCMC[-1,:] ; \n",
    "                \n",
    "                len_subj = len(X)\n",
    "                self.XALL[iterazione, subject-1, :len_subj] = X   #self.PMCMC.X_PMCMC[-1,:]\n",
    "                \n",
    "            # controllare in C se sbaglio qui... ossia itero due volte        \n",
    "            if iterazione <= self.M1:\n",
    "                #senza lambda visto che Qm non c'Ã¨\n",
    "                self.theta_choose = self.ottimizza_Log_Lik()\n",
    "            else:\n",
    "                self.lambda_ = 1/((iterazione - self.M1)**0.8)\n",
    "                self.theta_choose = self.ottimizza_con_storia()\n",
    "            \n",
    "            #if iterazione==0:\n",
    "             #   self.PMCMC = Particle_marginal_Metropolis_Hastings(number_of_iterations=100)\n",
    "                \n",
    "        return self.theta_choose\n",
    "    \n",
    "    def ottimizza_Log_Lik(self):\n",
    "        \n",
    "        #res = minimize(self.Compute_LogLikelihood , self.theta_choose,\n",
    "                             #method=\"L-BFGS-B\", bounds=self.bounds, maxi)  #options={'gtol': 1e-7, 'disp': True}\n",
    "        \n",
    "        #res = differential_evolution(self.Compute_LogLikelihood , bounds=self.bounds)\n",
    "        \n",
    "        #new_theta = fmin(-self.Compute_LogLikelihood , self.theta_choose)\n",
    "        res = minimize(self.Compute_LogLikelihood , self.theta_choose, method=\"Nelder-Mead\")\n",
    "                       \n",
    "        #print(new_theta)\n",
    "        print(res)\n",
    "        return res.x\n",
    "    \n",
    "    def ottimizza_con_storia(self):\n",
    "        res = minimize(self.Stochastic_Approximation , self.theta_choose, method=\"Nelder-Mead\")\n",
    "                       \n",
    "        print(res)\n",
    "        return res.x\n",
    "    \n",
    "    def Stochastic_Approximation(self, theta ):\n",
    "        for i in range(len(theta)):\n",
    "            if theta[i] > self.PARMAX[i] or theta[i] < self.PARMIN[i]:\n",
    "                return 1e+300\n",
    "        logPY = self.Compute_LogLikelihood(theta)\n",
    "        Qm_1 = self.PreviousQm(theta)\n",
    "        return Qm_1 + self.lambda_ * (logPY - Qm_1)\n",
    "        \n",
    "    def Compute_LogLikelihood(self, theta):\n",
    "        logpY = 0\n",
    "        #print(theta)\n",
    "        for i in range(len(theta)):\n",
    "            if theta[i] > self.PARMAX[i] or theta[i] < self.PARMIN[i]:\n",
    "                #print(i, theta[i], self.PARMAX[i], self.PARMIN[i])\n",
    "                return 1e+300\n",
    "        try:\n",
    "            self.phii_distr = multivariate_normal(theta[:2], np.diag(np.array(theta[2:4])**2))\n",
    "        except:\n",
    "            print(\"problema\")\n",
    "            print(theta)\n",
    "        for subj_ in range(1,7):\n",
    "            self.select_subj(subj_)\n",
    "\n",
    "            self.phi_i = self.PhiALL[self.iterazione,subj_ - 1, :]\n",
    "            self.X_i = self.XALL[self.iterazione, subj_ - 1, :len(self.timei)]\n",
    "            \n",
    "            pYigivenXi   = self.ModelCondDensityYgivenXevaluate(self.yobsi[0], self.X_i[0], theta);  pXigivenPhii = 1\n",
    "            for i_ in range(1, len(self.timei)):\n",
    "                \n",
    "                pYijgivenXij = self.ModelCondDensityYgivenXevaluate(self.yobsi[i_], self.X_i[i_], theta) \n",
    "                pYigivenXi   *=  pYijgivenXij\n",
    "                #print(pYigivenXi, pYijgivenXij)\n",
    "                \n",
    "                pXijgivenPhii = self.ModelTransitionDensityXevaluate(i_, theta)\n",
    "                pXigivenPhii = pXigivenPhii * pXijgivenPhii;\n",
    "                \n",
    "                \n",
    "            if pYigivenXi==0:\n",
    "                pYigivenXi=1e-300\n",
    "            \n",
    "            if pXigivenPhii==0:\n",
    "                pXigivenPhii = 1e-300\n",
    "                \n",
    "                \n",
    "            logpYigivenXi = np.log(pYigivenXi)\n",
    "            logpXigivenPhii = np.log(pXigivenPhii)     \n",
    "            logpPhii = np.log(self.ModelAprioriDensityPhievaluate(theta))\n",
    "            \n",
    "            logpY += (logpYigivenXi + logpXigivenPhii + logpPhii)\n",
    "            #print(subj_, logpY, logpYigivenXi, logpXigivenPhii, logpPhii)\n",
    "            #print(\"\\n\\n\")\n",
    "        return -logpY\n",
    "    \n",
    "    \n",
    "    def PreviousQm(self, theta):        \n",
    "        current_iteration = self.iterazione\n",
    "        self.iterazione = 0\n",
    "        Qm_1 = self.Compute_LogLikelihood(theta)\n",
    "        Qm = Qm_1\n",
    "        for it_ in range(1, current_iteration):\n",
    "            self.iterazione = it_\n",
    "            logPY = self.Compute_LogLikelihood(theta)\n",
    "            Qm += self.lambda_ * (logPY - Qm)\n",
    "        return Qm\n",
    "    \n",
    "    def ModelAprioriDensityPhievaluate(self, theta):\n",
    "        \n",
    "        return self.phii_distr.pdf(self.phi_i)\n",
    "    \n",
    "    def ModelCondDensityYgivenXevaluate(self, y_, x_, theta):\n",
    "        p = norm.pdf(y_, x_, theta[5])\n",
    "        if p==0: \n",
    "            p = 1e-300\n",
    "        return p\n",
    "    \n",
    "    def ModelTransitionDensityXevaluate(self, time_, theta):\n",
    "        beta = theta[4]\n",
    "        \n",
    "        uj = self.EulerStep(time_)\n",
    "        sj = beta * uj * np.sqrt(self.timei[time_] - self.timei[time_- 1])\n",
    "\n",
    "        p = norm.pdf(self.X_i[time_] ,  uj, sj)\n",
    "        if p == 0:\n",
    "            p = 1e-300      \n",
    "            \n",
    "        #print(p, uj, sj)\n",
    "        return p\n",
    "    \n",
    "    def EulerStep(self, time_):\n",
    "        time1 = self.timei[time_]; time0 = self.timei[time_ - 1]\n",
    "        x_t1 = self.X_i[time_ -1]\n",
    "        time = time0\n",
    "        deltat =  (time1 - time0)/ 100\n",
    "        while time < time1:\n",
    "            if (time1-time)>deltat:\n",
    "                dt = deltat\n",
    "            else:\n",
    "                dt = time1-time\n",
    "            x_t1 += self.ModelDrift(x_t1 )* dt\n",
    "            time += dt\n",
    "        return x_t1\n",
    "    \n",
    "    def ModelDrift(self, X):\n",
    "        return self.phi_i[0]* np.log(self.phi_i[1]/X)* X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "# self.PARMIN = [0.01, 1e-6, 0.0001, 1e-5, 0.0001, 1e-5] ; self.PARMAX = [1, 1e-1, 0.05, 1e-1, 1, 1e-3]\n",
    "theta = [0.3, 0.009, 0.2, 0.3, 0.3, 0.0001]   # [0.27, 0.0005, 0.04, 0.0035, 0.18, 0.0001]\n",
    "SAEM = Stochasti_Approximation_Expectation_Maximization()\n",
    "#SAEM.inizializza(theta)\n",
    "SAEM.run(theta)\n",
    "print(\"tempo esecuzione : %.5f \"% (time()-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.18643347e-01 0.00000000e+00]\n",
      " [0.00000000e+00 1.00064472e-10]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<scipy.stats._multivariate.multivariate_normal_frozen at 0x2941eac97b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([3.44446436e-01, 1.00032231e-05])\n",
    "v = np.diag(a**2)\n",
    "print(v)\n",
    "multivariate_normal(a,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3988.732773340162 1.96e-06 1e-07\n",
      "3977.2404065395585 8.1e-06 2.790714452729808e-07\n",
      "3966.3380607339523 1.16e-05 8.266127858042304e-07\n",
      "3944.75379119379 2.09e-05 5.89332296414592e-06\n",
      "3809.4213574947044 3.17e-05 1.3127471270614917e-06\n",
      "3580.1674469118648 5.57e-05 9.173236177406017e-06\n",
      "3606.1207448308946 7.03e-05 2.5352485909584112e-05\n",
      "3299.222991369751 0.000105 4.336241792509879e-05\n",
      "2384.981915622893 0.00015 4.856479723233464e-05\n",
      "2586.5151558918506 0.00022 0.00012690487770768922\n",
      "3488.5931354044405 0.000226 0.00017420269931519967\n",
      "3912.06944409895 0.000252 0.00023221108582295485\n"
     ]
    }
   ],
   "source": [
    "for i_ in range(0, len(SAEM.timei)):\n",
    "    print(SAEM.ModelCondDensityYgivenXevaluate(SAEM.yobsi[i_], SAEM.X_i[i_], theta), SAEM.yobsi[i_], SAEM.X_i[i_] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.96e-06, 8.10e-06, 1.16e-05, 2.09e-05, 3.17e-05, 5.57e-05,\n",
       "        7.03e-05, 1.05e-04, 1.50e-04, 2.20e-04, 2.26e-04, 2.52e-04]),\n",
       " array([1.00000000e-07, 2.79071445e-07, 8.26612786e-07, 5.89332296e-06,\n",
       "        1.31274713e-06, 9.17323618e-06, 2.53524859e-05, 4.33624179e-05,\n",
       "        4.85647972e-05, 1.26904878e-04, 1.74202699e-04, 2.32211086e-04]),\n",
       " array([ 4.4526,  5.6351,  6.4907,  7.6979,  8.4773,  9.2978, 10.692 ,\n",
       "        11.3167, 12.8289, 14.5346, 15.5006, 16.4679]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAEM.yobsi, SAEM.X_i, SAEM.timei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3, 0.009, 0.2, 0.3, 0.3, 0.0001] 754.2900883533351\n",
      "[2.82509615e-02 5.03784905e-05 2.97474419e-01 4.20632943e-05\n",
      " 5.47894204e-01 2.29341405e-04] inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umbertojunior\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:115: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "print(theta, SAEM.Compute_LogLikelihood(theta))\n",
    "print(SAEM.theta_choose, SAEM.Compute_LogLikelihood(SAEM.theta_choose))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import differential_evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 1),\n",
       " (1e-06, 0.1),\n",
       " (0.0001, 0.5),\n",
       " (1e-06, 1),\n",
       " (0.0001, 1),\n",
       " (1e-05, 0.001)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SAEM.bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Umbertojunior\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:103: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Umbertojunior\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:104: RuntimeWarning: divide by zero encountered in log\n",
      "C:\\Users\\Umbertojunior\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:112: RuntimeWarning: invalid value encountered in subtract\n",
      "  x = asanyarray(arr - arrmean)\n"
     ]
    }
   ],
   "source": [
    "res = differential_evolution(SAEM.Compute_LogLikelihood , bounds=SAEM.bounds)\n",
    "               \n",
    "print(res)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAEM.iterazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMCMC = Particle_marginal_Metropolis_Hastings(number_of_iterations=1000)\n",
    "start = time()\n",
    "PMCMC.sample_PMCMC(1, theta)\n",
    "print(\"tempo esecuzione PMCMC : %.4f sec\"% (time()-start))\n",
    "\n",
    "fig , (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.plot(np.arange(PMCMC.NI),PMCMC.phi_PMCMC[:,0])\n",
    "ax2.plot(np.arange(PMCMC.NI),PMCMC.phi_PMCMC[:,1])\n",
    "print(\"marginal Y pmcmc = \", np.max(PMCMC.marginal_pmcmc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMCMC.phi_PMCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_max = np.argmax(PMCMC.marginal_pmcmc)\n",
    "theta2 = [PMCMC.phi_PMCMC[ind_max,0], PMCMC.phi_PMCMC[ind_max,1] , 0.5, 35e-3, 0.1, 1e-5]\n",
    "PMCMC.fit_SMC(1, theta2)  #np.mean(PMCMC.phi_PMCMC[0,800:])\n",
    "plt.plot(PMCMC.timei, PMCMC.sampling_a_path().flatten(), \"b*\", markersize=5, label = \"sampled from SMC with phi max\")\n",
    "plt.plot(PMCMC.timei, PMCMC.X_PMCMC[-1,:], \"g*\", markersize=5, label = \"sampled from PMCMC\")\n",
    "plt.plot(PMCMC.timei, np.mean(PMCMC.X_PMCMC, axis=0), \"y*\", markersize=5, label = \"sampled from PMCMC mean\")\n",
    "\n",
    "plt.plot(PMCMC.timei, PMCMC.yobsi, \"r*\", markersize=12, label = \"observed\")\n",
    "plt.legend()\n",
    "\n",
    "print(\"\\n \\nalpha = %.4e  \\t  kappa = %.4e\"%(PMCMC.phi_PMCMC[ind_max,0], PMCMC.phi_PMCMC[ind_max,1]))\n",
    "print(\"marginal Y SMC sampled = \", PMCMC.marginal_y)\n",
    "\n",
    "print(\"\\n \\nalpha = %.4e  \\t  kappa = %.4e\"%(PMCMC.phi_PMCMC[-1,0], PMCMC.phi_PMCMC[-1,1]))\n",
    "print(\"marginal Y PMPCMC sampled = \", PMCMC.marginal_pmcmc[-1])\n",
    "\n",
    "print(\"\\n \\nalpha = %.4e  \\t  kappa = %.4e\"%(PMCMC.phi_PMCMC[ind_max,0], PMCMC.phi_PMCMC[ind_max,1]))\n",
    "print(\"marginal Y PMCMC max = \", PMCMC.marginal_pmcmc[np.argmax(PMCMC.marginal_pmcmc)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(PMCMC.marginal_pmcmc), PMCMC.marginal_pmcmc[np.argmax(PMCMC.marginal_pmcmc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PMCMC.marginal_pmcmc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fun = lambda x: (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "\n",
    "def fun_2(x):\n",
    "    return (x[0] - 1)**2 + (x[1] - 2.5)**2\n",
    "\n",
    "bnds = ((0,None), (0,None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = minimize(fun_2 , (4,0), method=\"L-BFGS-B\", bounds=bnds, options={'gtol': 1e-6, 'disp': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
